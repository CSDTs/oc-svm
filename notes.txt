2/12
See; https://hackernoon.com/one-class-classification-for-images-with-deep-features-be890c43455d
See: https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html

See: https://github.com/onnx/models#image_classification
for layers, note MobileNet and ShuffleNet

for a good way to use CNNs on images as features and then pass
to the OC-SVM for training, prediction

The issue is that we don't really understand the feature space, depending on
the CNN, we have these texture basises, not sure how to manipulate or explain that

Could have to students learn the basis? Would be easier if it was better grounded
--

2/14
See Skorch for working in pytorch
https://skorch.readthedocs.io/en/stable/user/installation.html

So there's something of a slight decision point,
The first hackernoon reference shows an end to end way to train on OC SVM with CNN features,
using Keras. But I've been advised to use PyTorch. I also want to get results ASAP.
There is also a deep OC features approach, here: https://github.com/PramuPerera/DeepOneClass
it uses Caffe though.

Okay so I think I should just reproduce the tutorial above and then swap in my dataaset and
report on results, set up an API somewhere
--
2/18

Okay, so what I'll do here is reproduce https://hackernoon.com/one-class-classification-for-images-with-deep-features-be890c43455d
within this cookie cutter data science frame work

note, vscode hot tip, fn+shift  on  mac in ipython will recall the previously entered command w/o 
scrolling up in the current command
-
note that tensorflow has no support for GPUs on macs (not NVIDIA) :___(
    this means if i run this elsewhere I should make sure I'm using the GPU'ed tensorflow
    or run w/in a Google colab
--
I'm starting to think that if i want to have results in hand before 5pm I might be
better off just busting this out in ipython, save the output and port to a the cookie cutter
reproducibale format later.
--
k, let's try it ...

okay I get
(oc-svm) bash-3.2$ python extract_features.py 
Using TensorFlow backend.
[INFO] loading network...
2020-02-18 15:14:22.733788: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-18 15:14:22.796471: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fc9ebc3c6c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-18 15:14:22.796496: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
/Users/kwamepr/.local/share/virtualenvs/oc-svm-EfKF6l7S/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.
  warnings.warn('The output shape of `ResNet50(include_top=False)` '
Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5
94658560/94653016 [==============================] - 4s 0us/step

but note
```
The output of the max-pooling layer has a volume shape of 7 x 7 x 512 which we flatten into a feature vector of 21,055-dim.
```
which suggests that I should do pool=max
see:
https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py#L256-L266
pool = 'max'

we should see a 7 x 7 512 matrix, flatted into a 21,055 dim feature vector
(for one image!?)
--
anyway, let's re-run with this 
works
-
say what now???

(oc-svm) bash-3.2$ ls -l output/validation.csv 
-rw-r--r--  1 kwamepr  staff  0 Feb 18 15:26 output/validation.csv
--
(oc-svm) bash-3.2$ ls -l output/*
-rw-r--r--  1 kwamepr  staff    0 Feb 18 15:26 output/evaluation.csv
-rw-r--r--  1 kwamepr  staff  261 Feb 18 15:26 output/le.cpickle
-rw-r--r--  1 kwamepr  staff    0 Feb 18 15:26 output/training.csv
-rw-r--r--  1 kwamepr  staff    0 Feb 18 15:26 output/validation.csv
---
note: https://cv-tricks.com/keras/understand-implement-resnets/
see the data generater shear, zoom , flip tricks

okay, so from the above there a couple of things to try:
a) Theyuse an avg pool, the write up from the code says a max pool but
maybe that was a typo?
b) Use no pool and see what happens, the pooling will change the shape.

I'll start w b since both writeups don't specify a pooling. Note this will
trigger the warning
-
I'll be, it's running
---
great got the following in the 5k replication

93/93 [==============================] - 120s 1s/step - loss: 2.9558e-05 - accuracy: 1.0000 - val_loss: 1.9939e-05 - val_accuracy: 0.9876
[INFO] evaluating network...
              precision    recall  f1-score   support

        food       0.99      0.98      0.99       500
    non_food       0.98      0.99      0.99       500

    accuracy                           0.99      1000
   macro avg       0.99      0.99      0.99      1000
weighted avg       0.99      0.99      0.99      1000
---
notice that classification metric is the same but the last epoch isn't as good
---
Now I need to
a) Figure out how to move training/test examples 
b) Figure out how to partially train a one class svm (I think?)
----
Okay, for SGD, I got

Epoch 3/3
78/78 [==============================] - 107s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 3.8343 - val_accuracy: 0.7232
[INFO] evaluating network...
/Users/kwamepr/.local/share/virtualenvs/oc-svm-EfKF6l7S/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

        fake       0.00      0.00      0.00       188
        real       0.73      1.00      0.84       500

    accuracy                           0.73       688
   macro avg       0.36      0.50      0.42       688
weighted avg       0.53      0.73      0.61       688
---
Which is really bad it seems, although it must be predicting some things are fake because 
it gets .73 on the real images, so I'm not sure. But it thinks all fake
images are real which ... isn't good.
---

Anyway, I'm trying to load any of the data and it's taking a looooooong time.
Eval is       327 mb 
training is   1g
validation is 325 mb

it looks like csv_feature_generator is doign something slightly unique,
maybe I should just workw with that instead of pandas; the nueral network 
does start training easily so it does load the data fine.

also, the generator will re-read data to fill up to the batch size,
wihch is really bad
---

see; https://stackoverflow.com/questions/40100176/can-dask-parralelize-reading-fom-a-csv-file
for loading dataframes in parallel with Dask,
 the followign works pretty quickly (~ 1 min for training data)
```
from dask.distributed import progress
from dask.distributed import Client
from dask import dd
client = Client()

df_dask = dd.read_csv(trainPath, sep=',', dtype=float, sample=int(2*256e3), blocksize="512MB")
df = progress(df_dask.compute(scheduler='processes'))
```

Rosebrock has a tutorial on deep learning anomaly detection 
here: https://www.pyimagesearch.com/2020/03/02/anomaly-detection-with-keras-tensorflow-and-deep-learning/
that uses autoencoder, autoencoder error as an anomaly dectector.
-
Okay, loading into an numpy array directly was wayyyyyyy easier
defintely a score for KISS. It's tough though because sustainability requires
good code design and eliminating code debt but research coding isn't really
meant to go outside of the basic proof of concept :(

I think I'm good, going to reorder the paths and start w the training data first
then run. From here I should be able to push the entire array, seperate out the labels,
into a one class classifier after pca'ing